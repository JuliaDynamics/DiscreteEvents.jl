<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Goldratt&#39;s Dice Game ¬∑ Simulate.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link href="../../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Simulate.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../../">Home</a></li><li><a class="toctext" href="../../../intro/">Getting started</a></li><li><a class="toctext" href="../../../approach/">Building models</a></li><li><a class="toctext" href="../../../usage/">Usage</a></li><li><span class="toctext">Examples</span><ul><li><a class="toctext" href="../../examples/">Overview</a></li><li><a class="toctext" href="../../greeting/">Two guys meet</a></li><li><a class="toctext" href="../../tabletennis/">Table tennis</a></li><li><a class="toctext" href="../../singleserver/">Single server</a></li><li><a class="toctext" href="../../postoffice/postoffice/">A Post Office</a></li><li class="current"><a class="toctext" href>Goldratt&#39;s Dice Game</a><ul class="internal"><li><a class="toctext" href="#An-assembly-line-1">An assembly line</a></li><li><a class="toctext" href="#Parametrizing-the-model-1">Parametrizing the model</a></li><li><a class="toctext" href="#Kanban-‚Ä¶-1">Kanban ‚Ä¶</a></li><li><a class="toctext" href="#Investigating-assembly-lines-1">Investigating assembly lines</a></li><li><a class="toctext" href="#Experimental-design-1">Experimental design</a></li><li><a class="toctext" href="#Data-analysis-1">Data analysis</a></li><li><a class="toctext" href="#Statistical-model-1">Statistical model</a></li><li><a class="toctext" href="#Final-remark-1">Final remark</a></li></ul></li><li><a class="toctext" href="../../house_heating/house_heating/">House heating</a></li></ul></li><li><a class="toctext" href="../../../internals/">Internals</a></li><li><a class="toctext" href="../../../troubleshooting/">Troubleshooting</a></li><li><a class="toctext" href="../../../history/">Release notes</a></li></ul></nav><article id="docs"><header><nav><ul><li>Examples</li><li><a href>Goldratt&#39;s Dice Game</a></li></ul><a class="edit-page" href="https://github.com/pbayer/Simulate.jl/blob/master/docs/src/examples/dicegame/dicegame.md"><span class="fa">ÔÇõ</span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Goldratt&#39;s Dice Game</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Goldratt&#39;s-Dice-Game-1" href="#Goldratt&#39;s-Dice-Game-1">Goldratt&#39;s Dice Game</a></h1><p>Goldratt&#39;s Dice Game from his business novel &quot;The Goal&quot; is a classical illustration that dependencies and statistical fluctuations diminish the throughput through a system.</p><p>Alex Rogo, the hero of the novel plays a game with five boys:</p><blockquote><p><em>While they go get the others, I figure out the details. The system I&#39;ve set up is intended to &quot;process&quot; matches. It does this by moving a quantity of match sticks out of their box, and through each of the bowls in succession. The dice determine how many matches can be moved from one bowl to the next. The dice represent the capacity of each resource, each bowl; the set of bowls are my dependent events, my stages of production. Each has exactly the same capacity as the others, but its actual yield will fluctuate somewhat.</em></p></blockquote><blockquote><p><em>In order to keep those fluctuations minimal, however, I decide to use only one of the dice. This allows the fluctuations to range from one to six. So from the first bowl, I can move to the next bowls in line any quantity of matches ranging from a minimum of one to a maximum of six.</em></p></blockquote><blockquote><p><em>Throughput in this system is the speed at which matches come out of the last bowl, Inventory consists of the total number of matches in all of the bowls at any time. And I&#39;m going to assume that market demand is exactly equal to the average number of matches that the system can process. Production capacity of each resource and market demand are perfectly in balance. So that means I now have a model of a perfectly balanced manufacturing plant.</em></p></blockquote><blockquote><p><em>Five of the boys decide to play. Besides Dave, there are Andy, Ben, Chuck, and Evan. Each of them sits behind one of the bowls. I find some paper and a pencil to record what happens. Then I explain what they&#39;re supposed to do.</em></p></blockquote><blockquote><p><em>&quot;The idea is to move as many matches as you can from your bowl to the bowl on your right. When it&#39;s your turn, you roll the die, and the number that comes up is the number of matches you can move. Got it?&quot;</em></p></blockquote><blockquote><p><em>They all nod. &quot;But you can only move as many matches as you&#39;ve got in your bowl. So if you roll a five and you only have two matches in your bowl, then you can only move two matches. And if it comes to your turn and you don&#39;t have any matches, then naturally you can&#39;t move any.&quot;</em></p></blockquote><blockquote><p><em>Eliyahu M Goldratt: The Goal.‚Äì 3rd ed, p. 105</em></p></blockquote><p>Then Rogo explains to the boys that with the die on average they should pass <code>3.5</code> matches through the system, so after twenty cycles they should have got an output of seventy.</p><p><img src="../DiceGame.png" alt="The Dice Game"/></p><h2><a class="nav-anchor" id="An-assembly-line-1" href="#An-assembly-line-1">An assembly line</a></h2><p>As Goldratt described it, the game is done in a fixed cycle ‚Äì no asynchronism here and no need for a discrete-event-simulation. But more realistically it could be seen as an assembly line with buffers between the five workers:</p><p><img src="../assembly_line.png" alt="assembly line"/></p><p>The workers take on average 3.5 time units for processing an item and they are admonished to work as fast as possible. To implement it, we need some data structure for workers ‚Ä¶</p><pre><code class="language-julia">using Simulate, Distributions, DataFrames, Random

mutable struct Worker
    nr::Int64              # worker number
    clk::Clock
    input::Channel  
    output::Channel
    dist::Distribution     # distribution of processing time
    retard::Float64        # worker retard factor, 1: no retardation, &gt;1: retardation
    done::Int64            # number of finished items

    Worker(nr, clk, input, output, dist, perform) = new(nr, clk, input, output, dist, 1/perform, 0)
end</code></pre><p>‚Ä¶ and a function representing their operation. The buffers are represented by channels. Then we build the system by creating workers and connecting them by channels. We start the work processes with their respective data and run the simulation.</p><pre><code class="language-julia">stats(t::Float64, nr::Int64, len::Int64) = push!(df, (t, nr, len))  ## write buffersize to dataframe

function work(w::Worker, stat::Bool)
    job = take!(w.input)
    stat ? stats(tau(w.clk), w.nr, length(w.input.data)) : nothing
    delay!(w.clk, rand(w.dist) * w.retard)
    put!(w.output, job)
    stat ? stats(tau(w.clk), w.nr+1, length(w.output.data)) : nothing
    w.done += 1
end

reset!(ùê∂)
Random.seed!(1234)                 # seed random number generator
df = DataFrame(time=Float64[], channel=Int[], length=Int[])

C = [Channel{Int64}(Inf) for i in 1:6]    # create 6 channels
j = reverse(Array(1:8))
for i in 5:-1:2                    # seed channels 2:5 each with 2 inventory items
    put!(C[i], j[(i-1)*2])
    put!(C[i], j[(i-1)*2-1])
end
for i in 9:1000                    # put other 992 jobs into channel 1
    put!(C[1], i)
end

W = [Worker(i, ùê∂, C[i], C[i+1], Uniform(0.5, 6.5), 1.0) for i in 1:5]
for i in 1:5
    process!(SP(i, work, W[i], true))
end
@time run!(ùê∂, 1000)</code></pre><p>0.261483 seconds (115.06 k allocations: 4.404 MiB)<br/>&quot;run! finished with 1390 clock events, 0 sample steps, simulation time: 1000.0&quot;</p><pre><code class="language-julia">length(C[6].data)                    # how much got produced?</code></pre><p>272</p><pre><code class="language-julia">1000/272</code></pre><p>3.676470588235294</p><p>After running for 1000 time units, we got 272 finished items in channel 6, meaning an average cycle time of 3.68, not 3.5 as expected. The expected throughput would have been 286 units, so the line produced only 95% of that, even under &quot;perfect&quot; conditions like unlimited supply, an in-process inventory to start with, infinite buffer sizes, a perfectly balanced line and equally performing workers without breaks ‚Ä¶ What happened?</p><pre><code class="language-julia">using Plots

function inventory_plot(n::Int64, title)
    for i ‚àà 2:n
        d = df[df.channel .== i, :]
        doplot = i == 2 ? plot : plot!
        doplot(d.time, d.length, label=&quot;channel$i&quot;)
    end
    title!(title)
    xlabel!(&quot;time&quot;)
    ylabel!(&quot;Inventory&quot;)
end
inventory_plot(5, &quot;In-Process-Inventory of Dice-Line&quot;)</code></pre><p><img src="../output_7_0.svg" alt="svg"/></p><p>We see that statistical fluctuations in processing times (the dice!) lead to wildly fluctuating buffers, overproduction of worker 1 (look at channel 2) and also to starvation of other workers down the line when their input buffers are empty. Let&#39;s calculate the inventory of unfinished goods in the line at the end of the simulation run:</p><pre><code class="language-julia">1000-length(C[1].data)-length(C[6].data)</code></pre><p>26</p><p>This gives an average of 6.5 inventory items in channels 2-5. But as we see in the plot, some channels are often empty, leading to some starvation.</p><h2><a class="nav-anchor" id="Parametrizing-the-model-1" href="#Parametrizing-the-model-1">Parametrizing the model</a></h2><p>For further investigations we parametrize our model. This is not easily done in graphically oriented simulators, but we can do it with <code>Simulate.jl</code>.</p><p>As parameters we take:</p><ul><li><code>n</code>: the length of the line (number of workers)</li><li><code>mw</code>: max WIP-buffer sizes (WIP is work in progress),</li><li><code>vp</code>: variation in processing times from item to item and,</li><li><code>vw</code>: variation between worker performance,</li><li><code>d</code>: the duration of the simulation run</li></ul><p>We give each simulation its own clock and channels variables so that it can be run in parallel on different threads.</p><pre><code class="language-julia">function dice_line( n::Int64, mw::Int64,
                    vp::Distribution, vw::Distribution;
                    d=1000, seed=1234, jobs=1000, stat::Bool=true )
    clk = Clock()
    Random.seed!(seed)                  # seed random number generator
    stat ? ( global df = DataFrame(time=Float64[], channel=Int[], length=Int[]) ) : nothing
    C = [Channel{Int64}(mw) for i in 1:n+1] # create n+1 channels with given buffer sizes
    C[1] = Channel{Int64}(Inf)                 # unlimited sizes for channels 1 and n+1
    C[n+1] = Channel{Int64}(Inf)
    j = reverse(Array(1:(n-1)*2))
    for i in n:-1:2                     # seed channels 2:(n-1) each with 2 inventory items
        C[i].sz_max &gt; 0 ? put!(C[i], j[(i-1)*2]) : nothing
        C[i].sz_max &gt; 1 ? put!(C[i], j[(i-1)*2-1]) : nothing
    end
    for i in ((n-1)*2+1):jobs           # put other jobs into channel 1
        put!(C[1], i)
    end

    wp = rand(vw, n)                    # calculate worker performance
    W = [Worker(i, clk, C[i], C[i+1], vp, wp[i]) for i in 1:n]
    for i in 1:n
        process!(clk, SP(i, work, W[i], stat))
    end
    info = run!(clk, d)
    return (info, clk.evcount, length(C[end].data))
end</code></pre><p>dice_line (generic function with 1 method)</p><h2><a class="nav-anchor" id="Kanban-‚Ä¶-1" href="#Kanban-‚Ä¶-1">Kanban ‚Ä¶</a></h2><p>Against too much inventory we have Kanban. So let&#39;s introduce maximum buffer sizes of 5 items. We have yet our five perfect workers without varying performance.</p><pre><code class="language-julia">using Printf
info, ev, res = dice_line(5, 5, Uniform(0.5, 6.5), Normal(1,0))
println(info)
println(res, &quot; items produced!&quot;)
@printf(&quot;%5.2f%s capacity utilization&quot;, 3.5*res/10, &quot;%&quot;)</code></pre><p>run! finished with 1341 clock events, 0 sample steps, simulation time: 1000.0<br/>266 items produced!<br/>93.10% capacity utilization</p><p>Uups! We throttled our system further, to an output of 266.</p><pre><code class="language-julia">inventory_plot(5, &quot;In-Process-Inventory of kanbanized Dice-Line&quot;)</code></pre><p><img src="../output_16_0.svg" alt="svg"/></p><p>But we got much less inventory in the system. The throttling occurs because with Kanban in-process-inventories get more often to zero. Seemingly Kanban is no solution for our throughput problem but constrains the system further. With Kanban we have reduced unpredictability and instability in inventory.</p><p>Let&#39;s pause a moment to look at what we have here: we got a small model with which we can simulate and analyze the impact of dependencies (line length and buffer sizes) and statistical fluctuations (in processing time and worker performance) on simple assembly lines like there are thousands in industry. This is no minor achievement.</p><h2><a class="nav-anchor" id="Investigating-assembly-lines-1" href="#Investigating-assembly-lines-1">Investigating assembly lines</a></h2><p>With the parametrized model we can do some investigations into the behaviour of assembly lines.</p><p>For that we take first some further simplification steps:</p><ol><li>We normalize the model by assuming a mean processing time of 1.</li><li>We choose a gamma distribution as more realistic for processing times than the uniform distribution, we used until now following Goldratt&#39;s example:</li></ol><pre><code class="language-julia">using StatsPlots, LaTeXStrings

for i in [2,3,5,10,15,20]
    doplot = i == 2 ? plot : plot!
    doplot(Gamma(i, 1/i), label=latexstring(&quot;a=$i, \\theta=$(round(1/i, digits=2))&quot;))
end
xlabel!(L&quot;\mathsf{processing\, time}&quot;)
ylabel!(L&quot;\mathsf{probability\, density}&quot;)
title!(latexstring(&quot;\\mathsf{Gamma\\, distribution,\\,} \\mu=1&quot;))</code></pre><p><img src="../output_19_0.svg" alt="svg"/></p><pre><code class="language-julia">@time info, ev, res = dice_line(5, 5, Gamma(10,1/10), Normal(1,0))
println(info)
println(res, &quot; items produced!&quot;)
@printf(&quot;y = %5.3f [1/t]&quot;, res/1000)</code></pre><p>1.060803 seconds (1.03 M allocations: 46.115 MiB, 1.03% gc time)<br/>run! finished with 4847 clock events, 0 sample steps, simulation time: 1000.0<br/>966 items produced!<br/>y = 0.966 [1/t]</p><pre><code class="language-julia">inventory_plot(5, &quot;In-Process-Inventory of kanbanized Dice-Line&quot;)</code></pre><p><img src="../output_21_0.svg" alt="svg"/></p><p>Before we go deeper into parameters, we have to check how much path dependence and statistical fluctuations vary the outcome. Therefore we repeat the simulation 30 times with different random number seeds and analyze the distribution of the outcome. As outcome we choose the throughput rate y [1/t] which is also an indicator for line performance.</p><pre><code class="language-julia">Random.seed!(1234)
s = abs.(rand(Int, 30))
tc = ones(30)
Threads.@threads for i = 1:30
    info, ev, res = dice_line(5, 5, Gamma(10,1/10), Normal(1,0), seed=s[i], jobs=1200, stat=false)
    tc[i] = res*0.001
end
ys = (Œº=mean(tc), œÉ=std(tc))
@printf(&quot;Œº: %5.3f, œÉ: %5.3f, LCL: %5.3f, UCL: %5.3f\n&quot;, ys.Œº, ys.œÉ, ys.Œº-3ys.œÉ, ys.Œº+3ys.œÉ)
plot(1:30, tc, title=&quot;throughput rate of various runs of dice line&quot;, xlabel=&quot;runs&quot;,
    ylabel=&quot;y [1/t]&quot;, legend=:none, lw=2)
hline!([ys.Œº, ys.Œº-3ys.œÉ, ys.Œº+3ys.œÉ], lc=:red)</code></pre><p>Œº: 0.967, œÉ: 0.006, LCL: 0.950, UCL: 0.984</p><p><img src="../output_23_1.svg" alt="svg"/></p><h2><a class="nav-anchor" id="Experimental-design-1" href="#Experimental-design-1">Experimental design</a></h2><p>Our response variable y seems to be under statistical control and its fluctuation is of the same order as the effects we are after. But with an experimental design those fluctuations should cancel out. We setup it up with:</p><ul><li><code>n</code>: number of workers, line length,</li><li><code>b</code>: buffersize between workers,</li><li><code>a</code>: shape parameter of gamma distribution of processing times (bigger a means less variation),</li><li><code>œÉ</code>: standard deviation of performance variation between workers.</li></ul><pre><code class="language-julia">using StatsModels, ExperimentalDesign

n = vcat(5:10,12:2:20)
b = 1:10
a = vcat(2,3,5:5:20)
œÉ = LinRange(0,0.1,5)

D = FullFactorial((n=n, b=b, a=a, œÉ=œÉ), @formula(y ~ n + b + a + œÉ), explicit = true)
size(D.matrix)</code></pre><p>(3300, 4)</p><p>We got a design matrix with 3300 rows for 3300 simulations! Let&#39;s do something else while the computer works:</p><pre><code class="language-julia">y = zeros(3300)
events = 0
t = @elapsed begin
    Threads.@threads for i = 1:3300
        p = Tuple(D.matrix[i, :])
        info, ev, res = dice_line(p[1], p[2], Gamma(p[3], 1/p[3]), Normal(1, p[4]), jobs=1200, stat=false )
        y[i] = res*0.001
        global events += ev
    end
end
@printf(&quot;Time elapsed: %5.2f minutes, %d events on %d threads&quot;, t/60, events, Threads.nthreads())</code></pre><p>Time elapsed: 17.47 minutes, 33558658 events on 4 threads</p><p>It takes over 17 minutes on 4 threads of a 2013 MacBook Pro and over <span>$33\times 10^6$</span> events.</p><h2><a class="nav-anchor" id="Data-analysis-1" href="#Data-analysis-1">Data analysis</a></h2><p>We put together a results table and do some exploratory data analysis:</p><pre><code class="language-julia">res = D.matrix
res.y = y
describe(y)</code></pre><pre><code class="language-none">Summary Stats:
Length:         3300
Missing Count:  0
Mean:           0.892569
Minimum:        0.633000
1st Quartile:   0.863750
Median:         0.904000
3rd Quartile:   0.937000
Maximum:        0.986000
Type:           Float64</code></pre><p>The performance of our simulated assembly lines varies between 0.637 and 0.986, which is a huge difference: The worst result is 35.8% below the best one!</p><pre><code class="language-julia">vcat(res[y .== maximum(y), :], res[y .== minimum(y), :])</code></pre><table><tr><th style="text-align: right">no</th><th style="text-align: right">n</th><th style="text-align: right">b</th><th style="text-align: right">a</th><th style="text-align: right">œÉ</th><th style="text-align: right">y</th></tr><tr><td style="text-align: right">1</td><td style="text-align: right">6</td><td style="text-align: right">7</td><td style="text-align: right">20</td><td style="text-align: right">0.0</td><td style="text-align: right">0.986</td></tr><tr><td style="text-align: right">2</td><td style="text-align: right">5</td><td style="text-align: right">10</td><td style="text-align: right">20</td><td style="text-align: right">0.0</td><td style="text-align: right">0.986</td></tr><tr><td style="text-align: right">3</td><td style="text-align: right">18</td><td style="text-align: right">1</td><td style="text-align: right">2</td><td style="text-align: right">0.05</td><td style="text-align: right">0.633</td></tr></table><p>The best performance is with the shortest lines, big buffer sizes, small variation in processing times and no variation in performance between workers. But this is just common sense. The worst performance is with a long line, minimum buffers and maximum variation in processing times and in performance between workers. But how big are the effects?</p><pre><code class="language-julia">@df res dotplot(:n, :y, title=&quot;line performance vs line length&quot;, xlabel=&quot;n&quot;, ylabel=&quot;y [1/t]&quot;,
    marker=(:circle, 2, 0.3, :none, 1, 0.3, :blue, :solid), legend=:none)
@df res boxplot!(:n, :y, marker=(:none, 0.3, 0.3, :blue, 2, 0.3, :blue, :solid), fill=(0, 0.2, :blue))</code></pre><p><img src="../output_33_0.svg" alt="svg"/></p><pre><code class="language-julia">@df res dotplot(:b, :y, title=&quot;line performance vs buffer size&quot;, xlabel=&quot;b&quot;, ylabel=&quot;y [1/t]&quot;,
    marker=(:circle, 2, 0.3, :none, 1, 0.3, :blue, :solid), legend=:none)
@df res boxplot!(:b, :y, marker=(:none, 0.3, 0.3, :blue, 2, 0.3, :blue, :solid), fill=(0, 0.2, :blue))</code></pre><p><img src="../output_34_0.svg" alt="svg"/></p><pre><code class="language-julia">@df res dotplot(:a, :y, title=&quot;line performance vs processing time variation&quot;, xlabel=&quot;a (bigger a: less variation)&quot;,
    ylabel=&quot;y [1/t]&quot;, marker=(:circle, 2, 0.3, :none, 1, 0.3, :blue, :solid), legend=:none)
@df res boxplot!(:a, :y, marker=(:none, 0.3, 0.3, :blue, 2, 0.3, :blue, :solid), fill=(0, 0.2, :blue))</code></pre><p><img src="../output_35_0.svg" alt="svg"/></p><pre><code class="language-julia">x = Int.(round.(res.œÉ*40))
@df res dotplot(x, :y, title=&quot;line performance vs worker performance variation&quot;, xlabel=L&quot;\sigma&quot;, ylabel=&quot;y [1/t]&quot;,
    marker=(:circle, 2, 0.3, :none, 1, 0.3, :blue, :solid), legend=:none)
@df res boxplot!(x, :y, marker=(:none, 0.3, 0.3, :blue, 2, 0.3, :blue, :solid), fill=(0, 0.2, :blue))
xticks!(collect(0:4), string.(round.(œÉ, digits=3)))</code></pre><p><img src="../output_36_0.svg" alt="svg"/></p><p>Buffer sizes and variation in processing time clearly have nonlinear effects while line length and performance variation between workers seem to have more linear ones. Small buffers and variation in processing time constrain the line the most and also are responsible for the worst performances. There seems to be also an interaction between those major two factors.</p><h2><a class="nav-anchor" id="Statistical-model-1" href="#Statistical-model-1">Statistical model</a></h2><p>We fit a linear model to the results and account for the nonlinearities with logarithmic terms:</p><pre><code class="language-julia">using GLM

ols = lm(@formula(y ~ 1 + n + log(1+b) + log(a) + œÉ), res)</code></pre><pre><code class="language-none">StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

y ~ 1 + n + :(log(1 + b)) + :(log(a)) + œÉ

Coefficients:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                Estimate   Std. Error   t value  Pr(&gt;|t|)    Lower 95%    Upper 95%
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
(Intercept)   0.738014    0.00235126   313.881     &lt;1e-99   0.733404     0.742624  
n            -0.00154928  9.81169e-5   -15.7902    &lt;1e-53  -0.00174166  -0.00135691
log(1 + b)    0.0576481   0.000897264   64.2488    &lt;1e-99   0.0558889    0.0594074
log(a)        0.050857    0.000564214   90.1378    &lt;1e-99   0.0497508    0.0519633
œÉ            -0.508588    0.0133498    -38.097     &lt;1e-99  -0.534763    -0.482413  
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</code></pre><p>All parameters are highly significant. We find then - as expected - that the b&amp;a-interaction between buffer size and variation in processing times is highly significant too:</p><pre><code class="language-julia">ols2 = lm(@formula(y ~ 1 + n + log(1+b)*log(a) + œÉ), res)</code></pre><pre><code class="language-none">StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

y ~ 1 + n + :(log(1 + b)) + :(log(a)) + œÉ + :(log(1 + b)) &amp; :(log(a))

Coefficients:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                        Estimate   Std. Error   t value  Pr(&gt;|t|)    Lower 95%    Upper 95%
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
(Intercept)           0.5992      0.00314399   190.586     &lt;1e-99   0.593035     0.605364  
n                    -0.00154928  7.21745e-5   -21.4658    &lt;1e-95  -0.00169079  -0.00140777
log(1 + b)            0.13696     0.00163887    83.5699    &lt;1e-99   0.133747     0.140173  
log(a)                0.123869    0.00144194    85.9039    &lt;1e-99   0.121041     0.126696  
œÉ                    -0.508588    0.00982009   -51.7906    &lt;1e-99  -0.527842    -0.489334  
log(1 + b) &amp; log(a)  -0.0417155   0.000788995  -52.8716    &lt;1e-99  -0.0432624   -0.0401685
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</code></pre><p>Then we can analyze the effects of the four parameters on line performance:</p><pre><code class="language-julia">x = LinRange(1,10,50)
for i in reverse(a)
    _n = fill(mean(n), length(x))
    _a = fill(i, length(x))
    _œÉ = fill(mean(œÉ), length(x))
    tmp = DataFrame(n=_n, b=x, a=_a, œÉ=_œÉ)
    _y = predict(ols2, tmp)
    doplot = i == 20 ? plot : plot!
    doplot(x, _y, label=&quot;a=$i&quot;)
end
title!(&quot;Effects of buffer size and processing time variation&quot;, legend=:bottomright)
xlabel!(&quot;b (buffer size)&quot;)
ylabel!(&quot;y [1/t]&quot;)</code></pre><p><img src="../output_42_0.svg" alt="svg"/></p><p>Buffer size and processing time variation have nonlinear effects and may account together for 26% line performance losses. This shows how important it is to increase buffer sizes with larger variation in processing times (smaller a). Only with small variation one can reduce buffers without loosing much performance.</p><pre><code class="language-julia">x = LinRange(5, 20, 50)
tmp = DataFrame(n=x, b=fill(mean(b), length(x)), a=fill(mean(a), length(x)),
    œÉ=fill(mean(œÉ), length(x)))
plot(x, predict(ols2, tmp), title=&quot;Effect of line length&quot;, xlabel=&quot;n (line length)&quot;,
    ylabel=&quot;y [1/t]&quot;, legend=:none)</code></pre><p><img src="../output_44_0.svg" alt="svg"/></p><p>This may account for 3% performance losses.</p><pre><code class="language-julia">x = LinRange(0,0.1,50)
tmp = DataFrame(n=fill(mean(n), length(x)), b=fill(mean(b), length(x)),
    a=fill(mean(a), length(x)), œÉ=x)
plot(x, predict(ols2, tmp), title=&quot;Effect of performance variation between workers&quot;,
    xlabel=L&quot;\sigma&quot;, ylabel=&quot;y [1/t]&quot;, legend=:none)</code></pre><p><img src="../output_46_0.svg" alt="svg"/></p><p>Variation in performance between workers may diminish line throughput by other 5%.</p><p>The four effects combined can account for 34% performance losses from best to worst. This is most of the 35.8% we found above. The rest is mostly statistical fluctuations.</p><h2><a class="nav-anchor" id="Final-remark-1" href="#Final-remark-1">Final remark</a></h2><p>Starting from a simple game and with only a quite small simulation model we could come to conclusions with a wide applicability for assembly lines. The performance differences in assembly lines are realistic ‚Äì I have seen them over and over in industry. And we didn&#39;t yet account for failures or supply shortfalls. The unawareness of those simple factors costs manufacturing industry billions.</p><p>The most interesting thing to note here is, that from seemingly quite unpredictable behaviour ‚Äì look at the inventory chart of the beginning ‚Äì emerge some quite predictable characteristics out of multiple discrete event simulations with parameter variation combined with some not too sophisticated statistics.</p><p>We could not have done those experiments and analyses with real lines as it is possible with simulations on a modern computer with <code>Julia</code> and <code>Simulate.jl</code>.</p><footer><hr/><a class="previous" href="../../postoffice/postoffice/"><span class="direction">Previous</span><span class="title">A Post Office</span></a><a class="next" href="../../house_heating/house_heating/"><span class="direction">Next</span><span class="title">House heating</span></a></footer></article></body></html>
